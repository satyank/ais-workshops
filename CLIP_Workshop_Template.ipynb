{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satyank/ais-workshops/blob/main/CLIP_Workshop_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# AIM CV Workshop\n",
        "\n",
        "---\n",
        "Go to file and click save a copy in drive\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "id": "title"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_hdr"
      },
      "source": [
        "## Runtime & Installs\n",
        "- Runtime -> Change runtime type ->  GPU\n",
        "- Run once, if NumPy shows as 2.x, restart session and re-run from top."
      ],
      "id": "setup_hdr"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup",
        "outputId": "9774940e-efdd-439e-fcb4-81e6b03019ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip -q install clip-anytorch ftfy==6.3.1\n",
        "import numpy as np, torch, clip\n",
        "print(\"NumPy:\", np.__version__, \"| Torch:\", torch.__version__)\n"
      ],
      "id": "setup",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy: 2.0.2 | Torch: 2.8.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "helpers_hdr"
      },
      "source": [
        "## Don't edit\n",
        "Code for the webcam\n"
      ],
      "id": "helpers_hdr"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "helpers"
      },
      "source": [
        "from IPython.display import display, Javascript, Image as IPyImage\n",
        "from google.colab import output\n",
        "import base64\n",
        "from PIL import Image\n",
        "import torch, clip\n",
        "\n",
        "def _take_photo_impl(filename='photo.jpg', quality=0.9):\n",
        "    js_code = f\"\"\"\n",
        "        async function takePhoto(quality) {{\n",
        "          const ID = 'webcam-div-unique';\n",
        "          const old = document.getElementById(ID);\n",
        "          if (old) old.remove();\n",
        "\n",
        "          const div = document.createElement('div');\n",
        "          div.id = ID;\n",
        "\n",
        "          const btn = document.createElement('button');\n",
        "          btn.textContent = 'Capture';\n",
        "          btn.style.fontSize = '16px';\n",
        "          btn.style.padding = '8px 14px';\n",
        "          btn.style.marginBottom = '8px';\n",
        "\n",
        "          const video = document.createElement('video');\n",
        "          video.style.display = 'block';\n",
        "          video.style.maxWidth = '100%';\n",
        "\n",
        "          div.appendChild(btn);\n",
        "          div.appendChild(video);\n",
        "          document.body.appendChild(div);\n",
        "\n",
        "          let stream = null;\n",
        "          try {{\n",
        "            stream = await navigator.mediaDevices.getUserMedia({{ video: true }});\n",
        "          }} catch (e) {{\n",
        "            alert('Ur camera is blocked. Allow access in URL bar at the top.');\n",
        "            return null;\n",
        "          }}\n",
        "\n",
        "          video.srcObject = stream;\n",
        "          await video.play();\n",
        "\n",
        "          google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "          await new Promise((resolve) => btn.onclick = resolve);\n",
        "\n",
        "          const canvas = document.createElement('canvas');\n",
        "          canvas.width = video.videoWidth;\n",
        "          canvas.height = video.videoHeight;\n",
        "          canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "          if (stream) stream.getVideoTracks().forEach(t => t.stop());\n",
        "          div.remove();\n",
        "\n",
        "          return canvas.toDataURL('image/jpeg', quality);\n",
        "        }}\n",
        "    \"\"\"\n",
        "    display(Javascript(js_code))\n",
        "\n",
        "    data = output.eval_js(f'takePhoto({quality})')\n",
        "    if not data:\n",
        "        return None\n",
        "\n",
        "    header, encoded = data.split(',', 1)\n",
        "    binary = base64.b64decode(encoded)\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "    return filename\n",
        "\n",
        "def take_photo():\n",
        "    fname = _take_photo_impl()\n",
        "    if fname:\n",
        "        display(IPyImage(fname))\n",
        "    return fname\n",
        "\n",
        "\n"
      ],
      "id": "helpers",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Action detection\n"
      ],
      "metadata": {
        "id": "ZihBiGVfz3v6"
      },
      "id": "ZihBiGVfz3v6"
    },
    {
      "cell_type": "code",
      "source": [
        "#function\n",
        "def recognize_zero_shot(image_path, actions, model, preprocess, device):\n",
        "  image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
        "  # Normalize features\n",
        "  with torch.no_grad():\n",
        "    image_features = model.encode_image(image)\n",
        "    text_inputs = clip.tokenize(actions).to(device)\n",
        "    text_features = model.encode_text(text_inputs)\n",
        "\n",
        "  # Compute similarity and pick best label\n",
        "  image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "  text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "  similarity = image_features @ text_features.T\n",
        "  pred_index = similarity.argmax().item()\n",
        "  return action[pred_index]\n"
      ],
      "metadata": {
        "id": "kpbwnO8fz2VR"
      },
      "id": "kpbwnO8fz2VR",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imports_hdr"
      },
      "source": [
        "## Imports\n"
      ],
      "id": "imports_hdr"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imports_tmpl"
      },
      "source": [
        "#write your imports here\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import torch\n",
        "import clip"
      ],
      "id": "imports_tmpl",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "load_hdr"
      },
      "source": [
        "## Load CLIP\n"
      ],
      "id": "load_hdr"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "load_tmpl",
        "outputId": "c9e31d71-5c18-4e82-8b4c-fd277cb2b452",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#pick device and load model\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "clip_model, preprocess = clip.load('ViT-B/32', device = device)\n",
        "clip_model.eval()\n",
        "print('Device', device)"
      ],
      "id": "load_tmpl",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "actions_hdr"
      },
      "source": [
        "## Define Actions\n",
        "Make a short list of actions to test."
      ],
      "id": "actions_hdr"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "actions_tmpl",
        "outputId": "0d6b7b33-6327-471d-90bf-a4498160ffc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ACTIONS = [\n",
        "    #action list\n",
        "    'A person waving',\n",
        "    'A person sitting still'\n",
        "    'A person doing a peace sign'\n",
        "]\n",
        "print('ACTIONS:', ACTIONS)"
      ],
      "id": "actions_tmpl",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACTIONS: ['A person waving', 'A person sitting stillA person doing a peace sign']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "capture_hdr"
      },
      "source": [
        "## Capture\n"
      ],
      "id": "capture_hdr"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "capture_tmpl",
        "outputId": "82c61e05-4a6d-4076-dd45-af05875f7c8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        }
      },
      "source": [
        "#our function is called take_photo()\n",
        "filename = take_photo()\n",
        "print('Captured:', ACTIONS)\n"
      ],
      "id": "capture_tmpl",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "          const ID = 'webcam-div-unique';\n",
              "          const old = document.getElementById(ID);\n",
              "          if (old) old.remove();\n",
              "\n",
              "          const div = document.createElement('div');\n",
              "          div.id = ID;\n",
              "\n",
              "          const btn = document.createElement('button');\n",
              "          btn.textContent = 'Capture';\n",
              "          btn.style.fontSize = '16px';\n",
              "          btn.style.padding = '8px 14px';\n",
              "          btn.style.marginBottom = '8px';\n",
              "\n",
              "          const video = document.createElement('video');\n",
              "          video.style.display = 'block';\n",
              "          video.style.maxWidth = '100%';\n",
              "\n",
              "          div.appendChild(btn);\n",
              "          div.appendChild(video);\n",
              "          document.body.appendChild(div);\n",
              "\n",
              "          let stream = null;\n",
              "          try {\n",
              "            stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
              "          } catch (e) {\n",
              "            alert('Ur camera is blocked. Allow access in URL bar at the top.');\n",
              "            return null;\n",
              "          }\n",
              "\n",
              "          video.srcObject = stream;\n",
              "          await video.play();\n",
              "\n",
              "          google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "          await new Promise((resolve) => btn.onclick = resolve);\n",
              "\n",
              "          const canvas = document.createElement('canvas');\n",
              "          canvas.width = video.videoWidth;\n",
              "          canvas.height = video.videoHeight;\n",
              "          canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "\n",
              "          if (stream) stream.getVideoTracks().forEach(t => t.stop());\n",
              "          div.remove();\n",
              "\n",
              "          return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4034177640.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#our function is called take_photo()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtake_photo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Captured:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mACTIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2916166881.py\u001b[0m in \u001b[0;36mtake_photo\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtake_photo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_take_photo_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIPyImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2916166881.py\u001b[0m in \u001b[0;36m_take_photo_impl\u001b[0;34m(filename, quality)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJavascript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'takePhoto({quality})'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "predict_hdr"
      },
      "source": [
        "## Predict\n"
      ],
      "id": "predict_hdr"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "predict_tmpl",
        "outputId": "b211e5ba-b6e2-40d0-b777-472ece46e6a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "if filename is None:\n",
        "  print('Photo not captured')\n",
        "else\n",
        "  # best = recognize_zero_shot.\n",
        "  print('Photo captured')\n"
      ],
      "id": "predict_tmpl",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "expected ':' (ipython-input-2751498639.py, line 3)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2751498639.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    else\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tweak_hdr"
      },
      "source": [
        "## Try new actions\n"
      ],
      "id": "tweak_hdr"
    }
  ]
}